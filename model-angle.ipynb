{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":67244,"databundleVersionId":7469085,"sourceType":"competition"}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-03-11T21:30:38.733144Z\",\"iopub.execute_input\":\"2024-03-11T21:30:38.733548Z\",\"iopub.status.idle\":\"2024-03-11T21:30:38.742529Z\",\"shell.execute_reply.started\":\"2024-03-11T21:30:38.733517Z\",\"shell.execute_reply\":\"2024-03-11T21:30:38.741123Z\"}}\nimport os\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom pathlib import Path\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.utils import Sequence\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input, BatchNormalization\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array, array_to_img\nfrom tensorflow.keras.metrics import BinaryAccuracy, Precision, Recall, AUC, MeanSquaredError, MeanAbsoluteError\nfrom tensorflow.keras.losses import BinaryCrossentropy, MeanSquaredError\nfrom skimage.transform import resize\nimport matplotlib.pyplot as plt\nimport json\nfrom tensorflow.keras.models import load_model\n\n\n\n# %% [markdown]\n# Read training images and labels \n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-11T21:30:41.098288Z\",\"iopub.execute_input\":\"2024-03-11T21:30:41.099432Z\",\"iopub.status.idle\":\"2024-03-11T21:30:41.105973Z\",\"shell.execute_reply.started\":\"2024-03-11T21:30:41.099383Z\",\"shell.execute_reply\":\"2024-03-11T21:30:41.104325Z\"}}\ndef get_dataset_path():\n    # Check if running in Kaggle\n    if 'KAGGLE_KERNEL_RUN_TYPE' in os.environ:\n        # Running in Kaggle kernel\n        return '/kaggle/input/machine-learning-in-science-ii-2024'\n    else:\n        # Running in a standalone Python script\n        return Path(__file__).parent\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-11T21:30:42.301523Z\",\"iopub.execute_input\":\"2024-03-11T21:30:42.301940Z\",\"iopub.status.idle\":\"2024-03-11T21:30:42.308772Z\",\"shell.execute_reply.started\":\"2024-03-11T21:30:42.301911Z\",\"shell.execute_reply\":\"2024-03-11T21:30:42.307347Z\"}}\n# Example usage:\ndataset_path = get_dataset_path()\nprint(f\"Dataset path: {dataset_path}\")\nprint(f\"{dataset_path}/training_data/training_data\")\nprint(f\"{dataset_path}/test_data/test_data\")\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-11T21:30:42.621016Z\",\"iopub.execute_input\":\"2024-03-11T21:30:42.621469Z\",\"iopub.status.idle\":\"2024-03-11T21:30:42.628971Z\",\"shell.execute_reply.started\":\"2024-03-11T21:30:42.621434Z\",\"shell.execute_reply\":\"2024-03-11T21:30:42.627579Z\"}}\ndef construct_images_path(directory_with_images):\n    filenames = os.listdir(directory_with_images) \n    image_paths = []\n    if any ('.png' in filename for filename in filenames):\n        for index, current_filename in enumerate(filenames):\n            image_path = f\"{directory_with_images}/{current_filename}\"\n            image_paths.append(image_path)\n            \n    return image_paths\n\n\n#construct_images_path(f\"{dataset_path}/training_data/training_data\")\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-11T21:30:43.878043Z\",\"iopub.execute_input\":\"2024-03-11T21:30:43.878435Z\",\"iopub.status.idle\":\"2024-03-11T21:30:43.883261Z\",\"shell.execute_reply.started\":\"2024-03-11T21:30:43.878406Z\",\"shell.execute_reply\":\"2024-03-11T21:30:43.882051Z\"}}\ndef build_training_directory_img(dataset_directory):\n    return f\"{dataset_directory}/training_data/training_data\"\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-11T21:30:44.087400Z\",\"iopub.execute_input\":\"2024-03-11T21:30:44.087814Z\",\"iopub.status.idle\":\"2024-03-11T21:30:44.094046Z\",\"shell.execute_reply.started\":\"2024-03-11T21:30:44.087784Z\",\"shell.execute_reply\":\"2024-03-11T21:30:44.093064Z\"}}\ndef build_test_directory_img(dataset_directory):\n    return f\"{dataset_directory}/test_data/test_data\"\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-11T21:30:46.474191Z\",\"iopub.execute_input\":\"2024-03-11T21:30:46.474610Z\",\"iopub.status.idle\":\"2024-03-11T21:30:46.502230Z\",\"shell.execute_reply.started\":\"2024-03-11T21:30:46.474579Z\",\"shell.execute_reply\":\"2024-03-11T21:30:46.500284Z\"}}\ndef build_images_path(dataset_directory):\n    training_images_directory = build_training_directory_img(dataset_directory)\n    test_images_directory = build_test_directory_img(dataset_directory)\n    training_images_path = construct_images_path(training_images_directory)\n    test_images_path = construct_images_path(test_images_directory)\n    return training_images_path,test_images_path\n\ntrain_img, test_img = build_images_path(dataset_path)\n# print(train_img) # print list with all images.\nprint(f\"Dataset path: \\n{train_img[0]} \\n{test_img[0]}\")\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-11T21:30:49.224761Z\",\"iopub.execute_input\":\"2024-03-11T21:30:49.225184Z\",\"iopub.status.idle\":\"2024-03-11T21:30:49.244336Z\",\"shell.execute_reply.started\":\"2024-03-11T21:30:49.225151Z\",\"shell.execute_reply\":\"2024-03-11T21:30:49.242928Z\"}}\ndef get_csv_labels(dataset_directory):\n    training_labels_relative_path = f\"{dataset_directory}/training_norm.csv\" # data frame path\n    training_labels = pd.read_csv(training_labels_relative_path)   # store the labels\n    return training_labels\n\ntraining_labels = get_csv_labels(dataset_path)\nprint(training_labels)\n\n# %% [markdown]\n# # Preprocessing.\n# Removing corrupted images.\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-11T21:30:51.665049Z\",\"iopub.execute_input\":\"2024-03-11T21:30:51.665552Z\",\"iopub.status.idle\":\"2024-03-11T21:31:03.388716Z\",\"shell.execute_reply.started\":\"2024-03-11T21:30:51.665503Z\",\"shell.execute_reply\":\"2024-03-11T21:31:03.387750Z\"}}\ndef find_corrupted_images(image_paths):\n    corrupted_indices = []\n    #print(image_paths)\n\n    for i, image_path in enumerate(image_paths):\n        try:\n            # Attempt to open the image\n            with Image.open(image_path) as img:\n                # Perform any additional checks if needed\n                pass\n        except (IOError, OSError, Exception) as e:\n            # Extract the index from the image_path\n            index = int(image_path.split('/')[-1].split('.png')[0])\n            # Handle the error (consider the image as corrupted)\n            print(f\"Error opening image {index}.png: {e}\")\n            corrupted_indices.append(index)\n    return corrupted_indices\n\n# Find corrupted images\ncorrupted_indices = find_corrupted_images(train_img)\n\n# Print the indices of corrupted images\nprint(\"Corrupted Image Indices:\", corrupted_indices)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-11T21:31:03.390559Z\",\"iopub.execute_input\":\"2024-03-11T21:31:03.391465Z\",\"iopub.status.idle\":\"2024-03-11T21:31:03.420994Z\",\"shell.execute_reply.started\":\"2024-03-11T21:31:03.391433Z\",\"shell.execute_reply\":\"2024-03-11T21:31:03.419836Z\"}}\nprint(len(train_img))\ntraining_labels_test = get_csv_labels(dataset_path)\n# Manual check if we removed the image IDs:\nimage_ids_to_check = [3884, 10171, 3141, 3999, 4895, 8285 , 1017, 13139, 13786, 13782          ]\nprint(training_labels_test)\n\n# Check if the image IDs exist in the list of cleaned image paths\nfor image_id in image_ids_to_check:\n    \n    filename_to_check = f'/kaggle/input/machine-learning-in-science-ii-2024/training_data/training_data/{image_id}.png'\n    if filename_to_check in train_img:\n        \n        print(f\"The file path for {filename_to_check} exists in the list.\")\n    else:\n        print(f\"The file path for {filename_to_check} does not exist in the list.\")\n\n# Check if the image IDs exist in the DataFrame\nfor image_id in image_ids_to_check:\n    # Check if the image ID exists in the 'image_id' column of data_labels_cleaned2\n    if image_id in training_labels_test['image_id'].tolist():\n        print(f\"The image ID {image_id} exists in training_labels_test.\")\n    else:\n        print(f\"The image ID {image_id} does not exist in training_labels_test.\")\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-11T21:31:08.289378Z\",\"iopub.execute_input\":\"2024-03-11T21:31:08.289849Z\",\"iopub.status.idle\":\"2024-03-11T21:31:08.297132Z\",\"shell.execute_reply.started\":\"2024-03-11T21:31:08.289813Z\",\"shell.execute_reply\":\"2024-03-11T21:31:08.295832Z\"}}\ndef remove_corrupted_data_labels(training_labels, corrupted_indices):\n    # Remove corrupted data from original data label set (training_norm.csv)\n    # Extract the 'image_id' column from the original DataFrame\n    image_ids = training_labels['image_id']\n    \n    # Identify the 'image_id' values for the corrupted images\n    corrupted_image_ids = image_ids.iloc[corrupted_indices].tolist()\n\n    # Check if each 'image_id' is in the list of corrupted 'image_id' values\n    is_not_corrupted = ~image_ids.isin(corrupted_image_ids)\n\n    # Filter the original DataFrame\n    data_labels_cleaned = training_labels[is_not_corrupted]\n\n    # Reset the index of the cleaned DataFrame\n    data_labels_cleaned = data_labels_cleaned.reset_index(drop=True)\n    \n    return data_labels_cleaned\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-11T21:31:09.154695Z\",\"iopub.execute_input\":\"2024-03-11T21:31:09.155103Z\",\"iopub.status.idle\":\"2024-03-11T21:31:09.161957Z\",\"shell.execute_reply.started\":\"2024-03-11T21:31:09.155071Z\",\"shell.execute_reply\":\"2024-03-11T21:31:09.161069Z\"}}\ndef remove_corrupted_data_images(dataset_directory, image_paths, corrupted_indices ):\n    # Remove corrupted images from original path list images:\n    # Remove corresponding image paths for corrupted images\n    training_images_directory = build_training_directory_img(dataset_directory)\n    filenames = os.listdir(training_images_directory)\n\n    # Initialize a list to store cleaned image paths\n    image_paths_cleaned = []\n\n    for current_filename in filenames:\n        image_id = int(current_filename.split('.')[0])\n        \n        # Check if the image_id is not in the list of corrupted indices\n        if image_id not in corrupted_indices:\n            image_path = os.path.join(training_images_directory, current_filename)\n            image_paths_cleaned.append(image_path)\n    return image_paths_cleaned\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-11T21:31:10.176513Z\",\"iopub.execute_input\":\"2024-03-11T21:31:10.176963Z\",\"iopub.status.idle\":\"2024-03-11T21:31:10.238428Z\",\"shell.execute_reply.started\":\"2024-03-11T21:31:10.176927Z\",\"shell.execute_reply\":\"2024-03-11T21:31:10.237121Z\"}}\ndef remove_corrupted_data(dataset_directory, training_labels, image_paths, corrupted_indices):\n    # Remove corrupted data from original data label set (training_norm.csv)\n    data_labels_cleaned = remove_corrupted_data_labels(training_labels, corrupted_indices)\n    # Remove corrupted images from original path list images:\n    image_paths_cleaned = remove_corrupted_data_images(dataset_directory, image_paths, corrupted_indices)\n    \n    # Return cleaned DataFrame and image paths\n    return data_labels_cleaned, image_paths_cleaned\n\n# Example usage\n\n\ndata_labels_cleaned, image_paths_cleaned = remove_corrupted_data(dataset_path, training_labels, train_img, corrupted_indices)\n\nprint(f'Labels: new:{len(data_labels_cleaned)} - old:{len(training_labels)}')\nprint(f'Images: new:{len(image_paths_cleaned)} - old:{len(train_img)}')\n\n\n# %% [markdown]\n# Check for incorect data.\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-11T21:38:20.186941Z\",\"iopub.execute_input\":\"2024-03-11T21:38:20.187392Z\",\"iopub.status.idle\":\"2024-03-11T21:38:24.155637Z\",\"shell.execute_reply.started\":\"2024-03-11T21:38:20.187359Z\",\"shell.execute_reply\":\"2024-03-11T21:38:24.154217Z\"}}\ndef remove_invalid_speed_data(data_labels, image_paths):\n    # Filter rows where 'speed' is not 0 or 1\n  \n    invalid_speed_filter = (data_labels['speed'] != 0) & (data_labels['speed'] != 1)\n    invalid_speed_rows = data_labels[invalid_speed_filter]\n    print(f'Removed rows with invalid speed values:\\n{invalid_speed_rows}')\n\n    # Get the indices of removed rows\n    removed_indices = invalid_speed_rows.index.tolist()\n    print(f'Indices of removed rows: {removed_indices}')\n\n    # Print the 'image_id' values of removed rows\n    removed_image_ids = invalid_speed_rows['image_id'].tolist()\n    print(f'Image_id values of removed rows: {removed_image_ids}')\n\n    # Filter rows where 'speed' is not 0 or 1\n    valid_speed_rows = data_labels[~invalid_speed_filter]\n\n    # Extract the 'image_id' column from valid speed rows\n    valid_image_ids = valid_speed_rows['image_id'].tolist()\n    print(f\"Number of entries with valid 'speed' values: {len(valid_speed_rows)}\")\n    # Filter image_paths based on valid image_ids\n    cleaned_image_paths = [path for path in image_paths if int(path.split('/')[-1].split('.')[0]) in valid_image_ids]\n     # Print paths that are not in cleaned_image_paths\n    not_included_paths = [path for path in image_paths if path not in cleaned_image_paths]\n    print(f'Paths not included in cleaned_image_paths:')\n    for path in not_included_paths:\n        print(path)\n    \n    # Return cleaned DataFrame and corresponding image paths\n    return valid_speed_rows, cleaned_image_paths\n\ndata_labels_cleaned2, image_paths_cleaned2 = remove_invalid_speed_data(data_labels_cleaned, image_paths_cleaned)\nprint(f': Labels: New count:{len(data_labels_cleaned2)} ? Previous count:{len(data_labels_cleaned)}')\nprint(f': Images: New count:{len(image_paths_cleaned2)} ? Previous count:{len(image_paths_cleaned)}')\nprint(f\"Type of image_paths_cleaned2 {type(image_paths_cleaned2)}.\")\n\n\n# %% [markdown]\n# # Plot Visual Inspection: \n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-11T21:31:20.779432Z\",\"iopub.execute_input\":\"2024-03-11T21:31:20.779842Z\",\"iopub.status.idle\":\"2024-03-11T21:31:23.649305Z\",\"shell.execute_reply.started\":\"2024-03-11T21:31:20.779809Z\",\"shell.execute_reply\":\"2024-03-11T21:31:23.648191Z\"}}\n# Create a figure and axes for subplots\nfig, axes = plt.subplots(2, 4, figsize=(20, 10))\n\n# Plot the first box plot for 'angle'\ndata_labels_cleaned['angle'].plot(kind='box', ax=axes[0, 0])\naxes[0, 0].set_title('Distribution of Angle - DataFrame 1')\n\n# Plot the first box plot for 'speed'\ndata_labels_cleaned['speed'].plot(kind='box', ax=axes[0, 1])\naxes[0, 1].set_title('Distribution of Speed - DataFrame 1')\n\n# Histogram for 'angle' in DataFrame 1\ndata_labels_cleaned['angle'].plot(kind='hist', bins=20, ax=axes[0, 2])\naxes[0, 2].set_title('Histogram of Angle - DataFrame 1')\n\n# Scatter plot of 'angle' against 'speed' in DataFrame 1\naxes[0, 3].scatter(data_labels_cleaned['angle'], data_labels_cleaned['speed'])\naxes[0, 3].set_title('Scatter Plot: Angle vs Speed - DataFrame 1')\naxes[0, 3].set_xlabel('Angle')\naxes[0, 3].set_ylabel('Speed')\n\n# Plot the second box plot for 'angle'\ndata_labels_cleaned2['angle'].plot(kind='box', ax=axes[1, 0])\naxes[1, 0].set_title('Distribution of Angle - DataFrame 2')\n\n# Plot the second box plot for 'speed'\ndata_labels_cleaned2['speed'].plot(kind='box', ax=axes[1, 1])\naxes[1, 1].set_title('Distribution of Speed - DataFrame 2')\n\n# Histogram for 'angle' in DataFrame 2\ndata_labels_cleaned2['angle'].plot(kind='hist', bins=20, ax=axes[1, 2])\naxes[1, 2].set_title('Histogram of Angle - DataFrame 2')\n\n# Scatter plot of 'angle' against 'speed' in DataFrame 2\naxes[1, 3].scatter(data_labels_cleaned2['angle'], data_labels_cleaned2['speed'])\naxes[1, 3].set_title('Scatter Plot: Angle vs Speed - DataFrame 2')\naxes[1, 3].set_xlabel('Angle')\naxes[1, 3].set_ylabel('Speed')\n\n# Adjust layout\nplt.tight_layout()\n\n# Show the plots\nplt.show()\n# Create a figure and axes for subplots\nfig, axes = plt.subplots(1, 2, figsize=(12, 5))\n\n# Scatter plot for 'angle'\naxes[0].scatter(range(len(data_labels_cleaned2['angle'])), data_labels_cleaned2['angle'])\naxes[0].set_title('Scatter Plot: Angle')\naxes[0].set_xlabel('Data Point Index')\naxes[0].set_ylabel('Angle')\n\n# Scatter plot for 'speed'\naxes[1].scatter(range(len(data_labels_cleaned2['speed'])), data_labels_cleaned2['speed'])\naxes[1].set_title('Scatter Plot: Speed')\naxes[1].set_xlabel('Data Point Index')\naxes[1].set_ylabel('Speed')\n\n# Adjust layout\nplt.tight_layout()\n\n# Show the plots\nplt.show()\n\n# %% [markdown]\n# # CNN MODEL\n# \n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-11T22:50:44.074295Z\",\"iopub.execute_input\":\"2024-03-11T22:50:44.074788Z\",\"iopub.status.idle\":\"2024-03-11T22:50:44.090998Z\",\"shell.execute_reply.started\":\"2024-03-11T22:50:44.074754Z\",\"shell.execute_reply\":\"2024-03-11T22:50:44.089736Z\"}}\ndef create_cnn_model_v3(image_shape, pool_size=(2, 2)):\n    \"\"\"\n    Creates two CNN models with the specified input shape.\n    \"\"\"\n    model_speed = Sequential([\n        Input(shape=image_shape + (3,), name='input_speed'),\n        Conv2D(32, (5, 5), activation='relu'),\n        MaxPooling2D(pool_size=pool_size),\n        Conv2D(64, (5, 5), activation='relu'),\n        MaxPooling2D(pool_size=pool_size),\n        Conv2D(128, (3, 3), activation='relu'),\n        MaxPooling2D(pool_size=pool_size),\n        Conv2D(256, (3, 3), activation='relu'),\n        Flatten(),\n        Dense(128, activation='relu'),\n        Dropout(0.5),\n        Dense(64, activation='relu'),\n        Dropout(0.5),\n        Dense(32, activation='relu'),\n        Dropout(0.5),\n        Dense(10, activation='relu'),\n        Dropout(0.5),\n        Dense(1, activation='sigmoid', name='output_speed')  # Output layer for 'speed'\n    ], name='model_speed')\n\n    model_angle = Sequential([\n        Input(shape=image_shape + (3,), name='input_angle'),\n        Conv2D(32, (5, 5), activation='relu'),\n        MaxPooling2D(pool_size=pool_size),\n        Conv2D(64, (5, 5), activation='relu'),\n        MaxPooling2D(pool_size=pool_size),\n        Conv2D(128, (3, 3), activation='relu'),\n        MaxPooling2D(pool_size=pool_size),\n        Conv2D(256, (3, 3), activation='relu'),\n        Flatten(),\n        Dense(128, activation='relu'),\n        Dropout(0.5),\n        Dense(64, activation='relu'),\n        Dropout(0.5),\n        Dense(32, activation='relu'),\n        Dropout(0.5),\n        Dense(10, activation='relu'),\n        Dropout(0.5),\n        Dense(1, activation='linear', name='output_angle')  # Output layer for 'angle'\n    ], name='model_angle')\n\n    print(\"Model Speed Summary:\")\n    model_speed.summary()\n    \n    print(\"\\nModel Angle Summary:\")\n    model_angle.summary()\n    \n    return model_speed, model_angle\n\n\n# %% [markdown]\n# # Data Generator class.\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-11T21:36:57.012506Z\",\"iopub.execute_input\":\"2024-03-11T21:36:57.012948Z\",\"iopub.status.idle\":\"2024-03-11T21:36:57.032538Z\",\"shell.execute_reply.started\":\"2024-03-11T21:36:57.012917Z\",\"shell.execute_reply\":\"2024-03-11T21:36:57.031148Z\"}}\nclass CustomDataGenerator(Sequence):\n    def __init__(self, file_paths, labels, batch_size, image_shape, output_label, augmentations=None, shuffle=True):\n        super().__init__()\n        self.file_paths = file_paths\n        self.labels = labels\n        self.batch_size = batch_size\n        self.image_shape = image_shape\n        self.output_label = output_label\n        self.augmentations = augmentations\n        self.shuffle = shuffle\n        self.indexes = np.arange(len(self.file_paths))\n\n\n    def __len__(self):\n        return int(np.ceil(len(self.file_paths) / self.batch_size))\n\n    def __getitem__(self, index):\n        start = index * self.batch_size\n        end = (index + 1) * self.batch_size\n        batch_paths = self.file_paths[start:end]\n\n        # Extract 'angle' or 'speed' column from the DataFrame as the batch labels\n        batch_labels = self.labels[self.output_label].iloc[start:end].values  \n\n        images = [self.load_and_augment_image(file_path) for file_path in batch_paths]\n        images = np.array(images)\n        output_values = np.array(batch_labels)  # Assign labels to output_values\n\n        return images, {self.output_label: output_values}\n\n    def on_epoch_end(self):\n        if self.shuffle:\n            np.random.shuffle(self.indexes)\n\n    def load_and_augment_image(self, file_path):\n        try:\n            # Load the image\n            img = load_img(file_path, target_size=self.image_shape)\n\n            # Ensure the image is in RGB format\n            img = img.convert(\"RGB\") # Convert to 3 channels image \n\n            # Convert the image to a NumPy array\n            img_array = img_to_array(img)\n\n            # Resize the image to the target size before augmentations\n            img_array = resize(img_array, self.image_shape)\n\n            # Print image shape before augmentations\n            #print(f\"Image shape before augmentations: {img_array.shape}\")\n\n            # Apply augmentations if specified\n            if self.augmentations:\n                img_array = self.augmentations.random_transform(img_array)\n\n            # Print image shape after augmentations\n            #print(f\"Image shape after augmentations: {img_array.shape}\")\n\n            # Normalize to [0, 1]\n            img_array = img_array / 255.0\n\n            return img_array\n        except Exception as e:\n            # Handle the exception (skip problematic image)\n            print(f\"Error loading image at path {file_path}: {e}\")\n            return None #self.placeholder  # \n        \n    def __iter__(self):\n            # Reset the generator at the beginning of each epoch\n            self.on_epoch_end()\n            return self\n\n    def __next__(self):\n            # Generate batches during iteration\n            index = 0\n            while index < len(self):\n                batch = self[index]\n                index += 1\n                return batch\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-11T21:31:28.774114Z\",\"iopub.execute_input\":\"2024-03-11T21:31:28.774525Z\",\"iopub.status.idle\":\"2024-03-11T21:31:28.781590Z\",\"shell.execute_reply.started\":\"2024-03-11T21:31:28.774495Z\",\"shell.execute_reply\":\"2024-03-11T21:31:28.780144Z\"}}\ndef create_data_generator(data_set, label_set, batch_size, image_shape, augmentations=None, output_label='speed'):  # if we don't specify the output_label, by default the output_label is speed.\n    return CustomDataGenerator(data_set, label_set, batch_size, image_shape, output_label, augmentations)\n\n\n# %% [markdown]\n# # Test dataset.\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-11T21:31:30.232388Z\",\"iopub.execute_input\":\"2024-03-11T21:31:30.232836Z\",\"iopub.status.idle\":\"2024-03-11T21:31:30.256388Z\",\"shell.execute_reply.started\":\"2024-03-11T21:31:30.232801Z\",\"shell.execute_reply\":\"2024-03-11T21:31:30.255247Z\"}}\nprint(len(image_paths_cleaned2))\n\n# Manual check if we removed the image IDs:\nimage_ids_to_check = [3884, 10171, 3141, 3999, 4895, 8285 , 1017, 13139, 13786, 13782          ]\nprint(data_labels_cleaned2)\n\n# Check if the image IDs exist in the list of cleaned image paths\nfor image_id in image_ids_to_check:\n    \n    filename_to_check = f'/kaggle/input/machine-learning-in-science-ii-2024/training_data/training_data/{image_id}.png'\n    if filename_to_check in image_paths_cleaned2:\n        \n        print(f\"The file path for {filename_to_check} exists in the list.\")\n    else:\n        print(f\"The file path for {filename_to_check} does not exist in the list.\")\n\n# Check if the image IDs exist in the DataFrame\nfor image_id in image_ids_to_check:\n    # Check if the image ID exists in the 'image_id' column of data_labels_cleaned2\n    if image_id in data_labels_cleaned2['image_id'].tolist():\n        print(f\"The image ID {image_id} exists in data_labels_cleaned2.\")\n    else:\n        print(f\"The image ID {image_id} does not exist in data_labels_cleaned2.\")\n\n# %% [markdown]\n# # Training\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-11T22:51:06.724218Z\",\"iopub.execute_input\":\"2024-03-11T22:51:06.724700Z\",\"iopub.status.idle\":\"2024-03-11T22:51:06.735776Z\",\"shell.execute_reply.started\":\"2024-03-11T22:51:06.724656Z\",\"shell.execute_reply\":\"2024-03-11T22:51:06.734302Z\"}}\ndef build_training_validation_and_evaluation_sets(train_image_paths, data_labels, image_shape, batch_size, eval_split, train_val_split):\n\n\n    # Split into training and validation sets our data set [images and labels]\n    train_set, val_set, train_labels, val_labels = train_test_split(\n        train_image_paths,\n        data_labels,\n        test_size=train_val_split[1],\n        random_state=42, # 42 is a random value \n        #stratify=data_labels['speed'] # We want to make sure that we have similar distribution of of the target variable ('speed') \n                                      # is similar in both the training and validation sets.\n    )\n  \n    # Split validation set into evaluation sets for speed and angle\n    eval_set_speed, eval_set_angle, eval_labels_speed, eval_labels_angle = train_test_split(\n        val_set,\n        val_labels,\n        test_size=eval_split,\n        random_state=42, # 42 is a random value \n        #stratify=data_labels['speed'] # We want to make sure that we have similar distribution of of the target variable ('speed') \n                                      # is similar in both the training and validation sets.\n    )\n   # Additional processing as needed (e.g., loading images, data augmentation) - Here we can add more images if we'll need.\n\n    # Print summary\n    print(f\"\\nFound {len(train_image_paths)} images.\")\n    print(f\"Using {len(train_set)} ({round(len(train_set) / len(train_image_paths) * 100, 1)}%) for training.\")\n    print(f\"Using {len(val_set)} ({round(len(val_set) / len(train_image_paths) * 100, 1)}%) for validation.\")\n    print(f\"Using {len(eval_set_speed)} ({round(len(eval_set_speed) / len(train_image_paths) * 100, 1)}%) for evaluation of speed.\")\n    print(f\"Using {len(eval_set_angle)} ({round(len(eval_set_angle) / len(train_image_paths) * 100, 1)}%) for evaluation of angle.\")\n    #print(train_set)\n\n    # Additional return statements as needed\n    return train_set, val_set, eval_set_speed, eval_set_angle, train_labels, val_labels, eval_labels_speed, eval_labels_angle\n\n\n# %% [markdown]\n# \n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-11T22:51:09.330300Z\",\"iopub.execute_input\":\"2024-03-11T22:51:09.333184Z\",\"iopub.status.idle\":\"2024-03-11T22:51:09.339969Z\",\"shell.execute_reply.started\":\"2024-03-11T22:51:09.333135Z\",\"shell.execute_reply\":\"2024-03-11T22:51:09.338878Z\"}}\n# DATA HYPERPARAMETERS\nbatch_size = 64    # Use 32 for training.\nimage_shape = (int(240/2), int(320/2)) # Half the real size of the image.\neval_split = 0.1\ntrain_val_split = [0.8, 0.2] # [training_set %, valuation_set %]\n\n# TRAINING HYPERPARAMETERS \nlearning_rate = 0.001  # Specify your desired learning rate~ \nepochs = 100\nlogging = True # Set to True, the training process might log various metrics (such as loss and accuracy) for visualization and analysis using TensorBoard.\npool_size=(2, 2)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-11T22:51:10.477544Z\",\"iopub.execute_input\":\"2024-03-11T22:51:10.478600Z\",\"iopub.status.idle\":\"2024-03-11T22:51:10.820982Z\",\"shell.execute_reply.started\":\"2024-03-11T22:51:10.478557Z\",\"shell.execute_reply\":\"2024-03-11T22:51:10.819776Z\"}}\n# Create the model\n\nmodel_speed, model_angle = create_cnn_model_v3(image_shape, pool_size)\n\n# Compile the model\n\nmodel_speed.compile(\n    optimizer='Adam',\n    loss='binary_crossentropy',  # for binary classification\n    metrics=[\n        BinaryAccuracy(name='accuracy'),\n        Precision(name='precision'),\n        Recall(name='recall'),\n        AUC(name='auc'),\n        MeanSquaredError(name='mse'),\n        MeanAbsoluteError(name='mae')\n    ]\n)\n# Compile the model\nmodel_angle.compile(\n    optimizer='Adam',\n    loss='mean_squared_error',  # for regression\n    metrics=[\n        MeanSquaredError(name='mse'),\n        MeanAbsoluteError(name='mae')\n    ]\n)\n\n\n# %% [markdown]\n# Save compiled models and metrics configuration.  -- for later use! - Not for kaggle competition.\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-11T22:51:16.589305Z\",\"iopub.execute_input\":\"2024-03-11T22:51:16.589784Z\",\"iopub.status.idle\":\"2024-03-11T22:51:16.747125Z\",\"shell.execute_reply.started\":\"2024-03-11T22:51:16.589738Z\",\"shell.execute_reply\":\"2024-03-11T22:51:16.746078Z\"}}\n# Save the compiled models but not trained.\n#model_speed.save('full_CNN_model_speed.h5')\nmodel_angle.save('full_CNN_model_angle.h5')\n# Save the metrics configuration before training.\n\nmetrics_config_speed = {\n    \"optimizer\": 'Adam',\n    \"loss\": 'binary_crossentropy',\n    \"metrics\": [\n        'accuracy',\n        'precision',\n        'recall',\n        'auc',\n        'mse',\n        'mae'\n    ]\n}\n\nmetrics_config_angle = {\n    \"optimizer\": 'Adam',\n    \"loss\": 'mean_squared_error',\n    \"metrics\": [\n        'mse',\n        'mae'\n    ]\n}\nwith open('metrics_config_speed.json', 'w') as f:\n    json.dump(metrics_config_speed, f)\n\nwith open('metrics_config_angle.json', 'w') as f:\n    json.dump(metrics_config_angle, f)\n\n# %% [markdown]\n# # ImageDataGenerator\n\n# %% [markdown]\n# channel_shift_range: Randomly shifts the color channels of the image by a specified percentage. It can be used to introduce variability in color.\n# \n# rotation_range: Randomly rotates the image by a specified angle in degrees. This helps the model become more robust to variations in object orientations.\n# \n# width_shift_range: Randomly shifts the image horizontally by a specified fraction of its width.\n# \n# height_shift_range: Randomly shifts the image vertically by a specified fraction of its height.\n# \n# shear_range: Applies a shear transformation to the image, changing the angle of a portion of the image.\n# \n# zoom_range: Randomly zooms into the image by a specified factor. This can simulate images taken from different distances.\n# \n# horizontal_flip: Randomly flips the image horizontally. This is often used to augment datasets when left-right symmetry is expected.\n# \n# vertical_flip: Randomly flips the image vertically. This is less commonly used but might be applicable in certain scenarios.\n# \n# fill_mode: Specifies the strategy used for filling in newly created pixels resulting from image transformations. The 'nearest' mode fills in new pixels with the nearest existing pixel value.\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-11T22:51:18.867392Z\",\"iopub.execute_input\":\"2024-03-11T22:51:18.867814Z\",\"iopub.status.idle\":\"2024-03-11T22:51:18.874264Z\",\"shell.execute_reply.started\":\"2024-03-11T22:51:18.867783Z\",\"shell.execute_reply\":\"2024-03-11T22:51:18.872963Z\"}}\n# Define augmentations\ndatagen = ImageDataGenerator(\n    channel_shift_range=0.02,\n    rotation_range=1,\n    width_shift_range=0.02,\n    height_shift_range=0.02,\n    shear_range=0.02,\n    zoom_range=0.02,\n    horizontal_flip=False,\n    vertical_flip=False,\n    fill_mode='nearest'\n)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-11T21:51:19.175368Z\",\"iopub.execute_input\":\"2024-03-11T21:51:19.175883Z\",\"iopub.status.idle\":\"2024-03-11T21:51:19.183981Z\",\"shell.execute_reply.started\":\"2024-03-11T21:51:19.175841Z\",\"shell.execute_reply\":\"2024-03-11T21:51:19.182667Z\"}}\nimage_paths_cleaned3 = [\n    \"/kaggle/input/machine-learning-in-science-ii-2024/training_data/training_data/9273.png\",\n    \"/kaggle/input/machine-learning-in-science-ii-2024/training_data/training_data/9292.png\",\n    \"/kaggle/input/machine-learning-in-science-ii-2024/training_data/training_data/11396.png\",\n    \"/kaggle/input/machine-learning-in-science-ii-2024/training_data/training_data/4353.png\",\n    \"/kaggle/input/machine-learning-in-science-ii-2024/training_data/training_data/7968.png\",\n    \"/kaggle/input/machine-learning-in-science-ii-2024/training_data/training_data/6490.png\",\n    \"/kaggle/input/machine-learning-in-science-ii-2024/training_data/training_data/5511.png\",\n    \"/kaggle/input/machine-learning-in-science-ii-2024/training_data/training_data/6262.png\",\n    \"/kaggle/input/machine-learning-in-science-ii-2024/training_data/training_data/2664.png\",\n    \"/kaggle/input/machine-learning-in-science-ii-2024/training_data/training_data/12329.png\"\n]\n\n# Extract indices from paths, convert to integers, and sort the list\nsorted_paths = sorted(image_paths_cleaned3, key=lambda x: int(x.split(\"/\")[-1].split(\".\")[0]))\n\n# Print the sorted paths\nfor path in sorted_paths:\n    print(path)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-11T21:51:20.476980Z\",\"iopub.execute_input\":\"2024-03-11T21:51:20.477700Z\",\"iopub.status.idle\":\"2024-03-11T21:51:20.499208Z\",\"shell.execute_reply.started\":\"2024-03-11T21:51:20.477664Z\",\"shell.execute_reply\":\"2024-03-11T21:51:20.497780Z\"}}\n# Create custom data generators\nsorted_paths = sorted(image_paths_cleaned2, key=lambda x: int(x.split(\"/\")[-1].split(\".\")[0]))\nimage_paths_cleaned2 = sorted_paths\n\n# %% [markdown]\n# Test/Debug\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-11T21:51:22.490339Z\",\"iopub.execute_input\":\"2024-03-11T21:51:22.490825Z\",\"iopub.status.idle\":\"2024-03-11T21:51:23.714168Z\",\"shell.execute_reply.started\":\"2024-03-11T21:51:22.490789Z\",\"shell.execute_reply\":\"2024-03-11T21:51:23.712771Z\"}}\n\ntrain_set, val_set, _, _, train_labels, val_labels, _, _ = build_training_validation_and_evaluation_sets(image_paths_cleaned2,\n                                                                data_labels_cleaned2,                                     \n                                                                   image_shape,\n                                                                   batch_size,\n                                                                    eval_split,\n                                                                   train_val_split  )\n# Print the first 10 elements from train_image_paths and data_labels\nprint(\"\\nFirst 10 elements of train_image_paths:\")\nfor i in range(min(10, len(image_paths_cleaned2))):\n    print(image_paths_cleaned2[i])\n  # Print the first 10 rows of data_labels\nprint(\"\\nFirst 10 rows of data_labels:\")\nprint(data_labels_cleaned2.head(10))\n    \nprint(type(train_labels))\n\ntrain_generator = create_data_generator(train_set, train_labels, batch_size, image_shape, augmentations=datagen, output_label='speed')\n\nval_generator = create_data_generator(val_set, val_labels, batch_size, image_shape, output_label='speed')\n\n# Fetch a single batch from the training generator\nfor index in range(1):\n    sample_batch_images, sample_batch_labels = train_generator[index]\n\n    # Display information about the batch\n    print(\"Sample Batch Information:\")\n    print(f\"Batch Shape - Images: {sample_batch_images.shape}, Labels: {sample_batch_labels['speed'].shape}\")\n    # Get the file path of the first sample in the batch\n\n    # Optionally, display some samples from the batch\n    if len(sample_batch_images) > 0:\n        # Display the first sample image\n        plt.imshow(sample_batch_images[0])\n        plt.title(f\"Sample Image - Speed: {sample_batch_labels['speed'][0]}\")\n        plt.show()\n\n    else:\n        print(\"No samples in the batch.\")\n    \n# Create custom data generators\ntrain_set, val_set, _, _, train_labels, val_labels, _, _ = build_training_validation_and_evaluation_sets(\n    image_paths_cleaned2, data_labels_cleaned2, image_shape, batch_size, eval_split, train_val_split\n)\n\n\nprint(f\"Length train_set: {len(train_set)}, Length train labels {len(train_labels)}.\")\nprint(f\"Length val_set: {len(val_set)}, Length val labels {len(val_labels)}.\")\n\ntrain_generator = create_data_generator(train_set, train_labels, batch_size, image_shape, augmentations=datagen, output_label='speed')\nval_generator = create_data_generator(val_set, val_labels, batch_size, image_shape, output_label='speed')\n\n# Get a batch from the training generator\nsample_images, sample_labels = train_generator[0]\n\n# Print the shape and values of labels\nprint(f\"Shape of labels: {sample_labels['speed'].shape}\")\nprint(\"Sample labels:\", sample_labels['speed'], \"len:\", len(sample_labels['speed']))\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-11T21:51:24.118816Z\",\"iopub.execute_input\":\"2024-03-11T21:51:24.119785Z\",\"iopub.status.idle\":\"2024-03-11T21:51:24.137540Z\",\"shell.execute_reply.started\":\"2024-03-11T21:51:24.119745Z\",\"shell.execute_reply\":\"2024-03-11T21:51:24.136336Z\"}}\n# Create custom data generators\ntrain_set_data, val_set_data, _, _, train_labels_data, val_labels_data, _, _ = build_training_validation_and_evaluation_sets(image_paths_cleaned2,\n                                                                  data_labels_cleaned2,                                     \n                                                                   image_shape,\n                                                                   batch_size,\n                                                                    eval_split,\n                                                                   train_val_split  )\n\n\n#train_generator_speed = create_data_generator(train_set_data, train_labels_data, batch_size, image_shape, augmentations=datagen, output_label='speed')\n#val_generator_speed = create_data_generator(val_set_data, val_labels_data, batch_size, image_shape, output_label='speed')\n\n\n\n# %% [markdown]\n# Test/ Debug\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-11T21:51:25.498523Z\",\"iopub.execute_input\":\"2024-03-11T21:51:25.499383Z\",\"iopub.status.idle\":\"2024-03-11T21:51:26.239888Z\",\"shell.execute_reply.started\":\"2024-03-11T21:51:25.499344Z\",\"shell.execute_reply\":\"2024-03-11T21:51:26.237272Z\"}}\nprint(train_set_data[0])\nprint(train_labels_data.iloc[[0]])\nprint(type(train_set_data),type(val_labels_data))\n\n\nprint(f\"Length train_set: {len(train_set)}, Length train labels {len(train_labels)}.\")\nprint(f\"Length val_set: {len(val_set)}, Length val labels {len(train_labels)}.\")\n\n# Check the first batch of the training generator\n#sample_batch = next(train_generator_speed)\n#print(f\"Sample batch shape: {sample_batch[0].shape}\")\n#print(f\"Sample batch labels: {sample_batch[1]}\")\n\n# Check the first batch of the validation generator\n#sample_val_batch = next(val_generator_speed)\n#print(f\"Sample validation batch shape: {sample_val_batch[0].shape}\")\n#print(f\"Sample validation batch labels: {sample_val_batch[1]}\")\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-11T21:51:27.436805Z\",\"iopub.execute_input\":\"2024-03-11T21:51:27.437269Z\",\"iopub.status.idle\":\"2024-03-11T22:06:49.895017Z\",\"shell.execute_reply.started\":\"2024-03-11T21:51:27.437234Z\",\"shell.execute_reply\":\"2024-03-11T22:06:49.892106Z\"}}\n# Fit the model for 'speed'\n#history_speed = model_speed.fit(\n #   train_generator_speed,\n  #  epochs=epochs,\n   # validation_data=val_generator_speed,\n    #verbose=1  # Set verbose to 0 to disable the default progress bar\n#)\n# Save the compiled model and trained.\n#model_speed.trainable = False\n#model_speed.save('full_CNN_model_speed_trained.h5')\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-11T22:08:31.984694Z\",\"iopub.execute_input\":\"2024-03-11T22:08:31.985134Z\",\"iopub.status.idle\":\"2024-03-11T22:08:32.749345Z\",\"shell.execute_reply.started\":\"2024-03-11T22:08:31.985088Z\",\"shell.execute_reply\":\"2024-03-11T22:08:32.748120Z\"}}\n# Create custom data generators\ntrain_generator_angle = create_data_generator(train_set_data, train_labels_data, batch_size, image_shape, augmentations=datagen, output_label='angle')\nval_generator_angle = create_data_generator(val_set_data, val_labels_data, batch_size, image_shape, output_label='angle')\n\n# Check the first batch of the training generator\nsample_batch = next(train_generator_angle)\nprint(f\"Sample batch shape: {sample_batch[0].shape}\")\nprint(f\"Sample batch labels: {sample_batch[1]}\")\n\n# Check the first batch of the validation generator\nsample_val_batch = next(val_generator_angle)\nprint(f\"Sample validation batch shape: {sample_val_batch[0].shape}\")\nprint(f\"Sample validation batch labels: {sample_val_batch[1]}\")\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-11T22:09:01.231914Z\",\"iopub.execute_input\":\"2024-03-11T22:09:01.232464Z\",\"iopub.status.idle\":\"2024-03-11T22:23:49.249980Z\",\"shell.execute_reply.started\":\"2024-03-11T22:09:01.232424Z\",\"shell.execute_reply\":\"2024-03-11T22:23:49.248710Z\"}}\n# Fit the model for 'angle'\nhistory_angle = model_angle.fit(\n    train_generator_angle,\n    epochs=epochs,\n    validation_data=val_generator_angle,\n    verbose=1  # Set verbose to 0 to disable the default progress bar\n)\n# Save the compiled models and trained.\nmodel_angle.trainable = False\nmodel_angle.save('full_CNN_model_angle_trained.h5')\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-11T22:32:50.577586Z\",\"iopub.execute_input\":\"2024-03-11T22:32:50.577998Z\",\"iopub.status.idle\":\"2024-03-11T22:32:50.838045Z\",\"shell.execute_reply.started\":\"2024-03-11T22:32:50.577969Z\",\"shell.execute_reply\":\"2024-03-11T22:32:50.836750Z\"}}\n#model_speed.trainable = False\n# Save the compiled model and trained.\n#model_speed.save('full_CNN_model_speed_trained.h5')\n#model_angle.trainable = False\n# Save the compiled models and trained.\n#model_angle.save('full_CNN_model_angle_trained.h5')\n\n# %% [markdown]\n# # Test on test data, make submission file!\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-11T22:38:12.020114Z\",\"iopub.execute_input\":\"2024-03-11T22:38:12.020964Z\",\"iopub.status.idle\":\"2024-03-11T22:38:12.030324Z\",\"shell.execute_reply.started\":\"2024-03-11T22:38:12.020926Z\",\"shell.execute_reply\":\"2024-03-11T22:38:12.029116Z\"}}\ndef load_test_images(test_data_dir, image_size=(200, 200)):\n    test_images = []\n    image_ids = []\n\n    for filename in os.listdir(test_data_dir):\n        if filename.endswith(\".png\"):\n            image_path = os.path.join(test_data_dir, filename)\n            img = Image.open(image_path)\n            # Convert to RGB mode with 24-bit depth\n            img = img.convert('RGB')\n\n            # Resize the image to the specified size\n            img = img.resize(image_size)\n            \n            # Convert the PIL Image to a NumPy array\n            img_array = np.array(img)\n            \n            # Ensure the shape is (height, width, channels)\n            if img_array.shape[-1] != 3:\n                img_array = np.transpose(img_array, (1, 0, 2))  # Swap height and width\n\n            test_images.append(img_array)\n            image_ids.append(filename.split(\".\")[0])  # Extracting the image ID from the filename\n\n    return np.array(test_images), image_ids\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-11T22:38:12.694498Z\",\"iopub.execute_input\":\"2024-03-11T22:38:12.695387Z\",\"iopub.status.idle\":\"2024-03-11T22:38:12.702864Z\",\"shell.execute_reply.started\":\"2024-03-11T22:38:12.695345Z\",\"shell.execute_reply\":\"2024-03-11T22:38:12.700650Z\"}}\nprint(build_test_directory_img(dataset_path))\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-11T22:45:28.784013Z\",\"iopub.execute_input\":\"2024-03-11T22:45:28.784439Z\",\"iopub.status.idle\":\"2024-03-11T22:45:28.793583Z\",\"shell.execute_reply.started\":\"2024-03-11T22:45:28.784409Z\",\"shell.execute_reply\":\"2024-03-11T22:45:28.791956Z\"}}\n#def test_cnn_model(model_speed, model_angle, dataset_path, target_size = (int(240/2), int(320/2))):\ndef test_cnn_model( model_angle, dataset_path, target_size = (int(240/2), int(320/2))):\n    # Load test data\n    test_images, image_ids = load_test_images(dataset_path, target_size)\n\n    # Make predictions using the trained model\n\n    predictions_angle = model_angle.predict(test_images)\n\n    print(f\" Angle: {predictions_angle}\")\n    # Flatten the nested lists\n  \n    flat_predictions_angle = [item for sublist in predictions_angle for item in sublist]\n    # Create a DataFrame with image IDs and predictions\n    results_df = pd.DataFrame({'image_id': image_ids, 'angle': flat_predictions_angle})\n    print(results_df)\n     # Save the results DataFrame to the new submission file\n    results_df.to_csv('Test_submission_angle.csv', index=False)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-03-11T22:45:30.380872Z\",\"iopub.execute_input\":\"2024-03-11T22:45:30.382074Z\",\"iopub.status.idle\":\"2024-03-11T22:45:53.270234Z\",\"shell.execute_reply.started\":\"2024-03-11T22:45:30.382025Z\",\"shell.execute_reply\":\"2024-03-11T22:45:53.269172Z\"}}\ntest_img_dir = build_test_directory_img(dataset_path)\ntest_cnn_model( model_angle,test_img_dir, image_shape )\n\n","metadata":{"_uuid":"c6cdb5eb-283b-4494-878c-ed09c24ac8f6","_cell_guid":"65eeab5b-0275-4783-a14e-87f50390b5bf","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-12T21:31:43.827989Z","iopub.execute_input":"2024-03-12T21:31:43.828389Z","iopub.status.idle":"2024-03-12T21:31:46.577776Z","shell.execute_reply.started":"2024-03-12T21:31:43.828345Z","shell.execute_reply":"2024-03-12T21:31:46.576530Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Dataset path: /kaggle/input/machine-learning-in-science-ii-2024\n/kaggle/input/machine-learning-in-science-ii-2024/training_data/training_data\n/kaggle/input/machine-learning-in-science-ii-2024/test_data/test_data\nDataset path: \n/kaggle/input/machine-learning-in-science-ii-2024/training_data/training_data/9273.png \n/kaggle/input/machine-learning-in-science-ii-2024/test_data/test_data/1017.png\n       image_id   angle  speed\n0             1  0.4375    0.0\n1             2  0.8125    1.0\n2             3  0.4375    1.0\n3             4  0.6250    1.0\n4             5  0.5000    0.0\n...         ...     ...    ...\n13788     13794  0.6250    1.0\n13789     13795  0.4375    1.0\n13790     13796  0.5625    0.0\n13791     13797  0.6250    0.0\n13792     13798  0.6875    1.0\n\n[13793 rows x 3 columns]\nError opening image 10171.png: cannot identify image file '/kaggle/input/machine-learning-in-science-ii-2024/training_data/training_data/10171.png'\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 111\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m corrupted_indices\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m# Find corrupted images\u001b[39;00m\n\u001b[0;32m--> 111\u001b[0m corrupted_indices \u001b[38;5;241m=\u001b[39m \u001b[43mfind_corrupted_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_img\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# Print the indices of corrupted images\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCorrupted Image Indices:\u001b[39m\u001b[38;5;124m\"\u001b[39m, corrupted_indices)\n","Cell \u001b[0;32mIn[2], line 99\u001b[0m, in \u001b[0;36mfind_corrupted_images\u001b[0;34m(image_paths)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, image_path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(image_paths):\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     98\u001b[0m         \u001b[38;5;66;03m# Attempt to open the image\u001b[39;00m\n\u001b[0;32m---> 99\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m img:\n\u001b[1;32m    100\u001b[0m             \u001b[38;5;66;03m# Perform any additional checks if needed\u001b[39;00m\n\u001b[1;32m    101\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIOError\u001b[39;00m, \u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    103\u001b[0m         \u001b[38;5;66;03m# Extract the index from the image_path\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/PIL/Image.py:3236\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3233\u001b[0m     filename \u001b[38;5;241m=\u001b[39m fp\n\u001b[1;32m   3235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[0;32m-> 3236\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3237\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   3239\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"def plot_loss(history):\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('Model Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend(['Train', 'Validation'], loc='upper right')\n    plt.show()\n    \nplot_loss(history_speed)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\ndf.to_csv(file_name, index=False)\n\nprint(f'CSV file \"{file_name}\" created successfully.')","metadata":{"execution":{"iopub.status.busy":"2024-03-12T21:32:23.045780Z","iopub.execute_input":"2024-03-12T21:32:23.046574Z","iopub.status.idle":"2024-03-12T21:32:23.083863Z","shell.execute_reply.started":"2024-03-12T21:32:23.046541Z","shell.execute_reply":"2024-03-12T21:32:23.082546Z"},"trusted":true},"execution_count":5,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mto_csv(file_name, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCSV file \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m created successfully.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"],"ename":"NameError","evalue":"name 'df' is not defined","output_type":"error"}]}]}